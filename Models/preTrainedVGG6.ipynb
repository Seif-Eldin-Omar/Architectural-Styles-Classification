{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "preprocessed_path = r'D:\\FUCK!!\\Pattern\\Project\\notebooks\\new_preprocessed_RGB_images' # Make sure this path is correct\n",
    "input_shape = (224, 224, 3)  # Standard VGG16 RGB input\n",
    "batch_size = 64\n",
    "num_epochs = 20 # Set a higher number of epochs, EarlyStopping will handle the actual stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Training Generator...\n",
      "Found 28400 images belonging to 10 classes.\n",
      "Found 28400 images belonging to 10 classes in training set.\n",
      "\n",
      "Setting up Validation Generator...\n",
      "Found 497 images belonging to 10 classes.\n",
      "Found 497 images belonging to 10 classes in validation set.\n",
      "\n",
      "Setting up Testing Generator...\n",
      "Found 268 images belonging to 10 classes.\n",
      "Found 268 images belonging to 10 classes in validation set.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# “val_dir” is the root of your test/validation folder\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "print(\"Setting up Training Generator...\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(preprocessed_path, 'train'),\n",
    "    target_size=input_shape[:2], # Use (224, 224)\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',         # Use sparse for sparse_categorical_crossentropy\n",
    "    color_mode='rgb',\n",
    "    shuffle=True             # Ensure images are loaded as RGB\n",
    ")\n",
    "print(f\"Found {train_generator.samples} images belonging to {train_generator.num_classes} classes in training set.\")\n",
    "\n",
    "print(\"\\nSetting up Validation Generator...\")\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(preprocessed_path, 'val'),\n",
    "    target_size=input_shape[:2], # Use (224, 224)\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',         # Use sparse for sparse_categorical_crossentropy\n",
    "    color_mode='rgb',            # Ensure images are loaded as RGB\n",
    "    shuffle=False                # No need to shuffle validation data\n",
    ")\n",
    "print(f\"Found {val_generator.samples} images belonging to {val_generator.num_classes} classes in validation set.\")\n",
    "\n",
    "print(\"\\nSetting up Testing Generator...\")\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    r\"D:\\FUCK!!\\Pattern\\Project\\notebooks\\new_preprocessed_RGB_images\\test\",\n",
    "    target_size=input_shape[:2], # Use (224, 224)\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',         # Use sparse for sparse_categorical_crossentropy\n",
    "    color_mode='rgb',            # Ensure images are loaded as RGB\n",
    "    shuffle=False                # No need to shuffle validation data\n",
    ")\n",
    "print(f\"Found {test_generator.samples} images belonging to {test_generator.num_classes} classes in validation set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of classes from the generator\n",
    "num_classes = train_generator.num_classes\n",
    "if num_classes != val_generator.num_classes:\n",
    "    print(\"Warning: Training and validation sets have different numbers of classes!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building VGG16 model...\n",
      "VGG16 base model loaded. Trainable: True\n",
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"VGG16_Transfer_Learning\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"VGG16_Transfer_Learning\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_avg_pool                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_avg_pool                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,984,522</span> (57.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,984,522\u001b[0m (57.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,988,426</span> (19.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,988,426\u001b[0m (19.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,996,096</span> (38.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,996,096\u001b[0m (38.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Build VGG16 Model ---\n",
    "print(\"\\nBuilding VGG16 model...\")\n",
    "# Load VGG16 base pre-trained on ImageNet, exclude top classification layer\n",
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# 2) Freeze early blocks, fine-tune later ones\n",
    "for layer in base_model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "print(f\"VGG16 base model loaded. Trainable: {base_model.trainable}\")\n",
    "\n",
    "# Create the new model head\n",
    "vgg16_model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(name='global_avg_pool'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(512, activation='relu', name='fc1'),\n",
    "    layers.Dropout(0.75, name='dropout_1'), # Dropout for regularization\n",
    "    layers.Dense(num_classes, activation='softmax', name='predictions') # Output layer\n",
    "], name=\"VGG16_Transfer_Learning\")\n",
    "\n",
    "# --- Compile Model ---\n",
    "# Use Adam optimizer with a specific, smaller learning rate\n",
    "optimizer = Adam(learning_rate=0.0001) # 0.0001 learning rate\n",
    "\n",
    "vgg16_model.compile(optimizer=optimizer,\n",
    "                    loss='sparse_categorical_crossentropy', # Use sparse CE with class_mode='sparse'\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Callbacks ---\n",
    "# Early stopping to prevent overfitting and stop training when val_loss stops improving\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,          # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,\n",
    "    restore_best_weights=True # Restore model weights from the epoch with the best val_loss\n",
    ")\n",
    "\n",
    "# Model checkpoint to save the best model found during training\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_vgg16_model.keras', # File path to save the model\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True, # Only save a model if `val_loss` has improved\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for up to 20 epochs (head only)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omarn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 40/443\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37:43\u001b[0m 6s/step - accuracy: 0.1907 - loss: 2.9716"
     ]
    }
   ],
   "source": [
    "# --- Train the Model (Head Only) ---\n",
    "print(f\"\\nStarting training for up to {num_epochs} epochs (head only)...\")\n",
    "history = vgg16_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size, # Ensure steps cover the dataset\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size, # Ensure steps cover the dataset\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[early_stopping, model_checkpoint] # Add the callbacks\n",
    ")\n",
    "\n",
    "print(\"\\nTraining finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(r'D:\\FUCK!!\\Pattern\\Project\\Models\\best_vgg16_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 268 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1) Prepare a “pure” test generator (no augmentation, only the same preprocessing)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    directory=r'D:/FUCK!!/Pattern/Project/notebooks/new_preprocessed_RGB_images/test',    # point this to your test‐folder \n",
    "    target_size=input_shape[:2],           # e.g. (224, 224)\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',\n",
    "    shuffle=False                           # important! so labels/preds align\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\omarn\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.6265 - loss: 26.7120\n",
      "\n",
      "Test loss: 33.0836 — Test accuracy: 0.5560\n"
     ]
    }
   ],
   "source": [
    "# 0) Clear any old graphs / functions\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 1) Reload your .keras model\n",
    "model = load_model(r'D:\\FUCK!!\\Pattern\\Project\\Models\\best_vgg16_model.keras')\n",
    "\n",
    "# 2) Re-compile it with the correct loss and metrics, running eagerly\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    "    run_eagerly=True    # ← this disables the tf.function wrapping\n",
    ")\n",
    "\n",
    "# 3) Now evaluate on your test generator (no need to pass steps)\n",
    "loss, acc = model.evaluate(test_gen, verbose=1)\n",
    "print(f\"\\nTest loss: {loss:.4f} — Test accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Achaemenid architecture       0.78      0.80      0.79        40\n",
      "American Foursquare architecture       0.86      0.84      0.85        37\n",
      "        American craftsman style       0.56      0.67      0.61        21\n",
      "   Ancient Egyptian architecture       0.00      0.00      0.00        18\n",
      "           Art Deco architecture       0.67      0.25      0.36        24\n",
      "        Art Nouveau architecture       0.53      0.50      0.51        20\n",
      "            Baroque architecture       0.42      0.89      0.57        27\n",
      "            Bauhaus architecture       0.36      1.00      0.53        27\n",
      "         Beaux-Arts architecture       1.00      0.07      0.13        29\n",
      "          Byzantine architecture       1.00      0.12      0.21        25\n",
      "\n",
      "                        accuracy                           0.56       268\n",
      "                       macro avg       0.62      0.51      0.46       268\n",
      "                    weighted avg       0.66      0.56      0.50       268\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[32  0  0  0  0  3  3  2  0  0]\n",
      " [ 0 31  3  0  0  0  0  3  0  0]\n",
      " [ 0  2 14  0  0  0  0  5  0  0]\n",
      " [ 7  0  4  0  0  3  1  3  0  0]\n",
      " [ 2  1  0  0  6  0  3 12  0  0]\n",
      " [ 0  0  0  0  0 10  3  7  0  0]\n",
      " [ 0  0  0  0  0  1 24  2  0  0]\n",
      " [ 0  0  0  0  0  0  0 27  0  0]\n",
      " [ 0  2  1  1  2  1 13  7  2  0]\n",
      " [ 0  0  3  0  1  1 10  7  0  3]]\n"
     ]
    }
   ],
   "source": [
    "# 3) (Optional) Get per‐class metrics\n",
    "#    - Predict class probabilities\n",
    "steps = int(np.ceil(test_gen.samples / batch_size))\n",
    "pred_probs = model.predict(\n",
    "    test_gen,\n",
    "    steps = steps,\n",
    "    verbose=1\n",
    ")\n",
    "#    - Turn them into predicted class indices\n",
    "pred_idxs = np.argmax(pred_probs, axis=1)\n",
    "true_idxs = test_gen.classes\n",
    "labels   = list(test_gen.class_indices.keys())\n",
    "\n",
    "#    - Classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(true_idxs, pred_idxs, target_names=labels))\n",
    "\n",
    "#    - Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(confusion_matrix(true_idxs, pred_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(); plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train_loss')\n",
    "plt.plot(history.history['val_accuracy'], label='val_loss')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend(); plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend(); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
